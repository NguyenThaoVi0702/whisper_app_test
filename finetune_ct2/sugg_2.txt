
lora-finetuning-job-s3  |   File "/usr/local/lib/python3.10/dist-packages/torch/amp/autocast_mode.py", line 44, in decorate_autocast
lora-finetuning-job-s3  |     return func(*args, **kwargs)
lora-finetuning-job-s3  |   File "/usr/local/lib/python3.10/dist-packages/peft/peft_model.py", line 818, in forward
lora-finetuning-job-s3  |     return self.get_base_model()(*args, **kwargs)
lora-finetuning-job-s3  |   File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
lora-finetuning-job-s3  |     return self._call_impl(*args, **kwargs)
lora-finetuning-job-s3  |   File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1762, in _call_impl
lora-finetuning-job-s3  |     return forward_call(*args, **kwargs)
lora-finetuning-job-s3  |   File "/usr/local/lib/python3.10/dist-packages/transformers/models/whisper/modeling_whisper.py", line 1776, in forward
lora-finetuning-job-s3  |     outputs = self.model(
lora-finetuning-job-s3  |   File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
lora-finetuning-job-s3  |     return self._call_impl(*args, **kwargs)
lora-finetuning-job-s3  |   File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1762, in _call_impl
lora-finetuning-job-s3  |     return forward_call(*args, **kwargs)
lora-finetuning-job-s3  |   File "/usr/local/lib/python3.10/dist-packages/transformers/models/whisper/modeling_whisper.py", line 1627, in forward
lora-finetuning-job-s3  |     encoder_outputs = self.encoder(
lora-finetuning-job-s3  |   File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
lora-finetuning-job-s3  |     return self._call_impl(*args, **kwargs)
lora-finetuning-job-s3  |   File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1762, in _call_impl
lora-finetuning-job-s3  |     return forward_call(*args, **kwargs)
lora-finetuning-job-s3  |   File "/usr/local/lib/python3.10/dist-packages/transformers/models/whisper/modeling_whisper.py", line 1069, in forward
lora-finetuning-job-s3  |     layer_outputs = encoder_layer(
lora-finetuning-job-s3  |   File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
lora-finetuning-job-s3  |     return self._call_impl(*args, **kwargs)
lora-finetuning-job-s3  |   File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1762, in _call_impl
lora-finetuning-job-s3  |     return forward_call(*args, **kwargs)
lora-finetuning-job-s3  |   File "/usr/local/lib/python3.10/dist-packages/transformers/models/whisper/modeling_whisper.py", line 622, in forward
lora-finetuning-job-s3  |     hidden_states, attn_weights, _ = self.self_attn(
lora-finetuning-job-s3  |   File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
lora-finetuning-job-s3  |     return self._call_impl(*args, **kwargs)
lora-finetuning-job-s3  |   File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1762, in _call_impl
lora-finetuning-job-s3  |     return forward_call(*args, **kwargs)
lora-finetuning-job-s3  |   File "/usr/local/lib/python3.10/dist-packages/transformers/models/whisper/modeling_whisper.py", line 511, in forward
lora-finetuning-job-s3  |     query_states = self._shape(self.q_proj(hidden_states), tgt_len, bsz)
lora-finetuning-job-s3  |   File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
lora-finetuning-job-s3  |     return self._call_impl(*args, **kwargs)
lora-finetuning-job-s3  |   File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1762, in _call_impl
lora-finetuning-job-s3  |     return forward_call(*args, **kwargs)
lora-finetuning-job-s3  |   File "/usr/local/lib/python3.10/dist-packages/peft/tuners/lora/layer.py", line 727, in forward
lora-finetuning-job-s3  |     result = result + lora_B(lora_A(dropout(x))) * scaling
lora-finetuning-job-s3  |   File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
lora-finetuning-job-s3  |     return self._call_impl(*args, **kwargs)
lora-finetuning-job-s3  |   File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1762, in _call_impl
lora-finetuning-job-s3  |     return forward_call(*args, **kwargs)
lora-finetuning-job-s3  |   File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/dropout.py", line 70, in forward
lora-finetuning-job-s3  |     return F.dropout(input, self.p, self.training, self.inplace)
lora-finetuning-job-s3  |   File "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py", line 1425, in dropout
lora-finetuning-job-s3  |     _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
lora-finetuning-job-s3  | RuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at "/pytorch/c10/cuda/CUDACachingAllocator.cpp":1016, please report a bug to PyTorch.
