
Filtered dataset size: 633414
Map:   0%|          | 0/633414 [00:00<?, ? examples/s]
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py", line 284, in __getattr__
    return self.data[item]
KeyError: 'ids'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/finetune_lora.py", line 50, in <module>
    dataset = dataset.map(prepare_dataset, remove_columns=dataset["train"].column_names, num_proc=1)
  File "/usr/local/lib/python3.10/dist-packages/datasets/dataset_dict.py", line 944, in map
    dataset_dict[split] = dataset.map(
  File "/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py", line 557, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py", line 3079, in map
    for rank, done, content in Dataset._map_single(**dataset_kwargs):
  File "/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py", line 3501, in _map_single
    for i, example in iter_outputs(shard_iterable):
  File "/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py", line 3475, in iter_outputs
    yield i, apply_function(example, i, offset=offset)
  File "/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py", line 3398, in apply_function
    processed_inputs = function(*fn_args, *additional_args, **fn_kwargs)
  File "/app/finetune_lora.py", line 47, in prepare_dataset
    batch["labels"] = tokenizer(batch["transcription"]).ids
  File "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py", line 286, in __getattr__
    raise AttributeError
AttributeError
