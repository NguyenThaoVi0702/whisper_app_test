ai_dev@ppe-nvidia-k8s-worker01:~$ docker logs -f lora-finetuning-job

==========
== CUDA ==
==========

CUDA Version 12.0.1

Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.

Loading adapter from ./my-whisper-medium-lora to continue training...
Trainable parameters:
trainable params: 6,553,600 || all params: 815,431,680 || trainable%: 0.8037
Downloading data: 100%|██████████| 105/105 [00:00<00:00, 22723.38files/s]
Generating train split: 634158 examples [02:58, 3552.60 examples/s]
Generating validation split: 7500 examples [00:02, 3479.76 examples/s]
Running mapping with proc = 1
Map: 100%|██████████| 634158/634158 [1:41:14<00:00, 104.40 examples/s]s]
Map: 100%|██████████| 7500/7500 [01:15<00:00, 98.71 examples/s]
Traceback (most recent call last):
  File "/app/finetune_lora.py", line 72, in <module>
    training_args = Seq2SeqTrainingArguments(
TypeError: Seq2SeqTrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'
