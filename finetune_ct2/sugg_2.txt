Of course. This is a much more practical workflow than mounting local files. Here is the new script designed to pull audio directly from S3, along with a detailed guide on how to run it.

1. The New Comparison Script (compare_models_s3.py)

This script is an evolution of the previous one. It now connects to S3 using the credentials from your environment, downloads the specified audio object, and then performs the comparison.

Save this code to a new file named compare_models_s3.py:

code
Python
download
content_copy
expand_less
# compare_models_s3.py

import os
import io
import logging
import argparse

import torch
import librosa
import boto3
from transformers import WhisperProcessor, WhisperForConditionalGeneration
from peft import PeftModel

# --- Basic Setup ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logging.getLogger("transformers").setLevel(logging.ERROR)
logging.getLogger("boto3").setLevel(logging.ERROR)
logging.getLogger("botocore").setLevel(logging.ERROR)

# --- Configuration Paths (Must match your training script) ---
BASE_MODEL_PATH = "/app/model"
FINETUNED_ADAPTER_PATH = "/app/outputs/vietbud500_adapter_final"
S3_BUCKET_NAME = os.environ.get("S3_BUCKET_NAME") # Bucket name should be passed as an env var

# --- S3 Client Function ---
def get_s3_client():
    """Initializes and returns a boto3 S3 client using env vars."""
    try:
        return boto3.client(
            "s3",
            endpoint_url=os.environ.get("S3_ENDPOINT_URL"),
            aws_access_key_id=os.environ.get("AWS_ACCESS_KEY_ID"),
            aws_secret_access_key=os.environ.get("AWS_SECRET_ACCESS_KEY"),
            region_name=os.environ.get("AWS_REGION"),
        )
    except Exception as e:
        raise ConnectionError(f"Failed to create S3 client: {e}")

def transcribe_audio_array(model, processor, audio_array, sampling_rate, device, model_dtype):
    """
    Takes a numpy audio array and returns the model's transcription.
    """
    try:
        # 1. Extract input features from the audio array
        input_features = processor(
            audio_array,
            sampling_rate=sampling_rate,
            return_tensors="pt"
        ).input_features
        
        # 2. Generate token ids
        logging.info("Generating transcription...")
        predicted_ids = model.generate(input_features.to(device, dtype=model_dtype))
        
        # 3. Decode token ids to text
        transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]
        return transcription

    except Exception as e:
        logging.error(f"Failed to transcribe audio array: {e}", exc_info=True)
        return "ERROR: Could not transcribe audio."

def main(s3_object_key):
    """
    Downloads an audio file from S3 and compares its transcription from
    the base and fine-tuned models.
    """
    if not S3_BUCKET_NAME:
        raise ValueError("The 'S3_BUCKET_NAME' environment variable is not set. Please set it before running.")

    device = "cuda" if torch.cuda.is_available() else "cpu"
    model_dtype = torch.bfloat16
    logging.info(f"Using device: {device} with dtype: {model_dtype}")

    # --- Load Processor and Models ---
    processor = WhisperProcessor.from_pretrained(BASE_MODEL_PATH, language="vi", task="transcribe")
    
    logging.info("Loading base Whisper model...")
    base_model = WhisperForConditionalGeneration.from_pretrained(
        BASE_MODEL_PATH, torch_dtype=model_dtype
    ).to(device)
    
    logging.info(f"Loading fine-tuned adapter from: {FINETUNED_ADAPTER_PATH}")
    fine_tuned_model = PeftModel.from_pretrained(base_model, FINETUNED_ADAPTER_PATH).to(device)
    
    base_model.eval()
    fine_tuned_model.eval()

    # --- Download Audio from S3 ---
    logging.info(f"Attempting to download s3://{S3_BUCKET_NAME}/{s3_object_key}")
    s3_client = get_s3_client()
    try:
        response = s3_client.get_object(Bucket=S3_BUCKET_NAME, Key=s3_object_key)
        audio_bytes = response['Body'].read()
        audio_array, sampling_rate = librosa.load(io.BytesIO(audio_bytes), sr=16000, mono=True)
        logging.info("Audio downloaded and loaded successfully.")
    except s3_client.exceptions.NoSuchKey:
        logging.error(f"S3 Error: The object key '{s3_object_key}' was not found in bucket '{S3_BUCKET_NAME}'.")
        return
    except Exception as e:
        logging.error(f"Failed to download or process audio from S3: {e}", exc_info=True)
        return

    # --- Run Inference and Compare ---
    print("\n" + "="*80)
    print("Transcribing with BASE model...")
    base_transcription = transcribe_audio_array(base_model, processor, audio_array, sampling_rate, device, model_dtype)

    print("\n" + "="*80)
    print("Transcribing with FINE-TUNED model...")
    finetuned_transcription = transcribe_audio_array(fine_tuned_model, processor, audio_array, sampling_rate, device, model_dtype)
    
    # --- Display Final Comparison ---
    print("\n" + "#"*30)
    print("###   MODEL COMPARISON   ###")
    print("#"*30)
    
    print(f"\nAudio Source: s3://{S3_BUCKET_NAME}/{s3_object_key}")
    
    print("\n[BASE MODEL TRANSCRIPTION]:")
    print(f"    '{base_transcription}'")

    print("\n[FINE-TUNED MODEL TRANSCRIPTION]:")
    print(f"    '{finetuned_transcription}'")
    print("\n")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Compare base and fine-tuned Whisper model transcriptions using an audio file from S3.")
    parser.add_argument("s3_key", type=str, help="The S3 object key (e.g., 'path/to/my_test_audio.wav') of the audio file to transcribe.")
    args = parser.parse_args()
    
    main(args.s3_key)
2. How to Run the Script

You will use the docker compose run command again. This time, instead of mounting a volume, you will pass an environment variable (-e) to specify the bucket name.

Command:

code
Bash
download
content_copy
expand_less
docker compose run --rm \
  -e S3_BUCKET_NAME="lhl-s3-a544-aipage-bbh" \
  finetuner python compare_models_s3.py "hist-audio/unseen-data/test_sample_1.wav"

Let's break this command down:

docker compose run --rm: Starts a new, temporary container for a service.

-e S3_BUCKET_NAME="lhl-s3-a544-aipage-bbh":

-e is the flag for setting an environment variable inside the container.

You are setting the variable S3_BUCKET_NAME to the value "lhl-s3-a544-aipage-bbh" (replace with your actual bucket name if different). The Python script will read this value.

finetuner: The name of the service to use from your docker-compose.yml file. This ensures the container has the correct image, GPU access, and all your other S3 credentials from your .env file.

python compare_models_s3.py "...": The command to execute.

python compare_models_s3.py: Runs the new script.

"hist-audio/unseen-data/test_sample_1.wav": This is the S3 object key that you want to test. Replace this with the actual path to your audio file within the bucket. The script receives this as a command-line argument.

This approach is cleaner and more scalable, allowing you to easily test any audio file in your S3 bucket without needing to modify volumes or move files around.
