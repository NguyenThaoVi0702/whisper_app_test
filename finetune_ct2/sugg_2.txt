# compare_models_s3.py

import os
import io
import logging
import argparse

import torch
import librosa
import boto3
from transformers import WhisperProcessor, WhisperForConditionalGeneration
from peft import PeftModel

# --- Basic Setup ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logging.getLogger("transformers").setLevel(logging.ERROR)
logging.getLogger("boto3").setLevel(logging.ERROR)
logging.getLogger("botocore").setLevel(logging.ERROR)

# --- Configuration Paths (Must match your training script) ---
BASE_MODEL_PATH = "/app/model"
FINETUNED_ADAPTER_PATH = "/app/outputs/vietbud500_adapter_final"
S3_BUCKET_NAME = os.environ.get("S3_BUCKET_NAME")

# --- S3 Client Function ---
def get_s3_client():
    """Initializes and returns a boto3 S3 client using env vars."""
    try:
        return boto3.client(
            "s3",
            endpoint_url=os.environ.get("S3_ENDPOINT_URL"),
            aws_access_key_id=os.environ.get("AWS_ACCESS_KEY_ID"),
            aws_secret_access_key=os.environ.get("AWS_SECRET_ACCESS_KEY"),
            region_name=os.environ.get("AWS_REGION"),
        )
    except Exception as e:
        raise ConnectionError(f"Failed to create S3 client: {e}")

def transcribe_audio_array(model, processor, audio_array, sampling_rate, device, model_dtype):
    """Takes a numpy audio array and returns the model's transcription."""
    try:
        input_features = processor(
            audio_array, sampling_rate=sampling_rate, return_tensors="pt"
        ).input_features
        
        logging.info("Generating transcription...")
        

        predicted_ids = model.generate(
            input_features.to(device, dtype=model_dtype),
            max_new_tokens=448  
        )
        
        transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]
        return transcription

    except Exception as e:
        logging.error(f"Failed to transcribe audio array: {e}", exc_info=True)
        return "ERROR: Could not transcribe audio."

def main(s3_object_key):
    if not S3_BUCKET_NAME:
        raise ValueError("The 'S3_BUCKET_NAME' environment variable is not set.")

    device = "cuda" if torch.cuda.is_available() else "cpu"
    model_dtype = torch.bfloat16
    logging.info(f"Using device: {device} with dtype: {model_dtype}")

    processor = WhisperProcessor.from_pretrained(BASE_MODEL_PATH, language="vi", task="transcribe")
    

    logging.info("Loading base model and applying adapter for FINE-TUNED version...")
    fine_tuned_model = WhisperForConditionalGeneration.from_pretrained(
        BASE_MODEL_PATH, torch_dtype=model_dtype
    )
    fine_tuned_model = PeftModel.from_pretrained(fine_tuned_model, FINETUNED_ADAPTER_PATH).to(device)
    fine_tuned_model.eval()

    # 2. Now, load a completely fresh, separate instance for the BASE version.
    logging.info("Loading a fresh BASE model instance...")
    base_model = WhisperForConditionalGeneration.from_pretrained(
        BASE_MODEL_PATH, torch_dtype=model_dtype
    ).to(device)
    base_model.eval()
    
    # --- Download Audio from S3 ---
    logging.info(f"Attempting to download s3://{S3_BUCKET_NAME}/{s3_object_key}")
    s3_client = get_s3_client()
    try:
        response = s3_client.get_object(Bucket=S3_BUCKET_NAME, Key=s3_object_key)
        audio_bytes = response['Body'].read()
        audio_array, sampling_rate = librosa.load(io.BytesIO(audio_bytes), sr=16000, mono=True)
        logging.info("Audio downloaded and loaded successfully.")
    except s3_client.exceptions.NoSuchKey:
        logging.error(f"S3 Error: The object key '{s3_object_key}' was not found in bucket '{S3_BUCKET_NAME}'.")
        return
    except Exception as e:
        logging.error(f"Failed to download or process audio from S3: {e}", exc_info=True)
        return

    # --- Run Inference and Compare ---
    print("\n" + "="*80)
    print("Transcribing with BASE model...")
    base_transcription = transcribe_audio_array(base_model, processor, audio_array, sampling_rate, device, model_dtype)

    print("\n" + "="*80)
    print("Transcribing with FINE-TUNED model...")
    finetuned_transcription = transcribe_audio_array(fine_tuned_model, processor, audio_array, sampling_rate, device, model_dtype)
    
    # --- Display Final Comparison ---
    print("\n" + "#"*30)
    print("###   MODEL COMPARISON   ###")
    print("#"*30)
    
    print(f"\nAudio Source: s3://{S3_BUCKET_NAME}/{s3_object_key}")
    
    print("\n[BASE MODEL TRANSCRIPTION]:")
    print(f"    '{base_transcription}'")

    print("\n[FINE-TUNED MODEL TRANSCRIPTION]:")
    print(f"    '{finetuned_transcription}'")
    print("\n")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Compare base and fine-tuned Whisper model transcriptions using an audio file from S3.")
    parser.add_argument("s3_key", type=str, help="The S3 object key (e.g., 'path/to/my_test_audio.wav') of the audio file to transcribe.")
    args = parser.parse_args()
    
    main(args.s3_key)
