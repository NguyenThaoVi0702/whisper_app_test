version: '3.8'

services:
  finetuner:
    image: finetune_whisper_lora:v3
    container_name: lora-finetuning-job-s3

    user: "${HOST_UID}:${HOST_GID}"

    env_file:
      - .env

    environment:
      - HF_HOME=/app/.cache/huggingface
      - TORCH_HOME=/app/.cache/torch
      - AWS_CA_BUNDLE=/app/ca-bundle.crt
      
      ### ADD THESE LINES ###
      # Redirect the Triton compiler cache to a writable directory we control.
      # This directly solves the PermissionError.
      - TRITON_CACHE_DIR=/app/.cache/triton
      # It's also good practice to redirect the numba cache.
      - NUMBA_CACHE_DIR=/app/.cache/numba

    working_dir: /app

    volumes:
      - .:/app
      - ./.cache:/app/.cache
      - ${ANNOTATIONS_FILE_PATH}:${ANNOTATIONS_FILE_IN_CONTAINER}:ro
      - ${S3_CA_BUNDLE_PATH}:/app/ca-bundle.crt:ro
      - /etc/passwd:/etc/passwd:ro
      - /etc/group:/etc/group:ro
      - ./outputs:/app/outputs

    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]
              device_ids: ['${MIG_DEVICE_UUID}']

    command: python3 finetune_lora.py
