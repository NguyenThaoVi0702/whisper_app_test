Transcribing with FINE-TUNED model...
2025-11-03 07:47:44,741 - INFO - Generating transcription...
2025-11-03 07:47:44,938 - ERROR - Failed to transcribe audio array: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 3,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 451. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
Traceback (most recent call last):
  File "/app/compare_models.py", line 49, in transcribe_audio_array
    predicted_ids = model.generate(
  File "/usr/local/lib/python3.10/dist-packages/peft/peft_model.py", line 823, in generate
    return self.get_base_model().generate(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/models/whisper/generation_whisper.py", line 755, in generate
    self._set_max_new_tokens_and_length(
  File "/usr/local/lib/python3.10/dist-packages/transformers/models/whisper/generation_whisper.py", line 1833, in _set_max_new_tokens_and_length
    raise ValueError(
ValueError: The length of `decoder_input_ids`, including special start tokens, prompt tokens, and previous tokens, is 3,  and `max_new_tokens` is 448. Thus, the combined length of `decoder_input_ids` and `max_new_tokens` is: 451. This exceeds the `max_target_positions` of the Whisper model: 448. You should either reduce the length of your prompt, or reduce the value of `max_new_tokens`, so that their combined length is less than 448.
